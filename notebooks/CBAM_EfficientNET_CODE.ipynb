{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 6631112,
          "sourceType": "datasetVersion",
          "datasetId": 3827977
        }
      ],
      "dockerImageVersionId": 31236,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook0db35760ac",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "imtkaggleteam_dental_radiography_path = kagglehub.dataset_download('imtkaggleteam/dental-radiography')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "aN1nBJqlr5ZA"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Multi-Model Dental X-Ray Classification with Attention Mechanisms\n",
        "EfficientNetB0 + SE/CBAM, MobileNetV2\n",
        "Focal Loss + TTA + Comprehensive Evaluation\n",
        "FINAL CORRECTED VERSION - IEEE ICME 2026\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import json\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import (confusion_matrix, classification_report, f1_score,\n",
        "                            matthews_corrcoef, roc_auc_score, roc_curve, auc,\n",
        "                            precision_recall_fscore_support)\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "from scipy.stats import wilcoxon, norm\n",
        "from collections import Counter\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.applications import (EfficientNetB0, MobileNetV2)\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mob_preprocess\n",
        "\n",
        "print(f\"TensorFlow Version: {tf.__version__}\")\n",
        "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\")\n",
        "\n",
        "# ---------- CONFIG ----------\n",
        "IMG_SIZE = 224\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 50\n",
        "SEED = 42\n",
        "TTA_STEPS = 6\n",
        "\n",
        "np.random.seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "\n",
        "# ---------- ATTENTION MODULES ----------\n",
        "def se_block(input_tensor, reduction=16):\n",
        "    \"\"\"Squeeze-and-Excitation Block\"\"\"\n",
        "    channels = input_tensor.shape[-1]\n",
        "    se = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    se = layers.Dense(channels // reduction, activation='relu')(se)\n",
        "    se = layers.Dense(channels, activation='sigmoid')(se)\n",
        "    se = layers.Reshape((1, 1, channels))(se)\n",
        "    return layers.Multiply()([input_tensor, se])\n",
        "\n",
        "def cbam_block(input_tensor, reduction=16):\n",
        "    \"\"\"Convolutional Block Attention Module\"\"\"\n",
        "    channels = input_tensor.shape[-1]\n",
        "\n",
        "    # Channel Attention\n",
        "    avg_pool = layers.GlobalAveragePooling2D()(input_tensor)\n",
        "    max_pool = layers.GlobalMaxPooling2D()(input_tensor)\n",
        "    avg_pool = layers.Reshape((1, 1, channels))(avg_pool)\n",
        "    max_pool = layers.Reshape((1, 1, channels))(max_pool)\n",
        "\n",
        "    shared_dense1 = layers.Dense(channels // reduction, activation='relu')\n",
        "    shared_dense2 = layers.Dense(channels, activation='sigmoid')\n",
        "\n",
        "    avg_out = shared_dense2(shared_dense1(avg_pool))\n",
        "    max_out = shared_dense2(shared_dense1(max_pool))\n",
        "\n",
        "    channel_attn = layers.Add()([avg_out, max_out])\n",
        "    channel_attn = layers.Reshape((1, 1, channels))(channel_attn)\n",
        "    channel_attn = layers.Multiply()([input_tensor, channel_attn])\n",
        "\n",
        "    # Spatial Attention\n",
        "    avg_pool_spatial = layers.Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(channel_attn)\n",
        "    max_pool_spatial = layers.Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(channel_attn)\n",
        "    spatial_attn = layers.Concatenate(axis=-1)([avg_pool_spatial, max_pool_spatial])\n",
        "    spatial_attn = layers.Conv2D(1, kernel_size=7, padding='same', activation='sigmoid')(spatial_attn)\n",
        "\n",
        "    return layers.Multiply()([channel_attn, spatial_attn])\n",
        "\n",
        "# ---------- MODEL BUILDERS ----------\n",
        "def build_efficientnet_vanilla(n_classes, img_size=IMG_SIZE):\n",
        "    \"\"\"EfficientNetB0 Baseline (No Attention)\"\"\"\n",
        "    base = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))\n",
        "    base.trainable = True\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(n_classes, activation='softmax')(x)\n",
        "    return models.Model(base.input, out, name='EfficientNetB0')\n",
        "\n",
        "def build_efficientnet_se(n_classes, img_size=IMG_SIZE):\n",
        "    \"\"\"EfficientNetB0 + SE Attention\"\"\"\n",
        "    base = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))\n",
        "    base.trainable = True\n",
        "    x = base.output\n",
        "    x = se_block(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(n_classes, activation='softmax')(x)\n",
        "    return models.Model(base.input, out, name='EfficientNetB0_SE')\n",
        "\n",
        "def build_efficientnet_cbam(n_classes, img_size=IMG_SIZE):\n",
        "    \"\"\"EfficientNetB0 + CBAM Attention\"\"\"\n",
        "    base = EfficientNetB0(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))\n",
        "    base.trainable = True\n",
        "    x = base.output\n",
        "    x = cbam_block(x)\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(n_classes, activation='softmax')(x)\n",
        "    return models.Model(base.input, out, name='EfficientNetB0_CBAM')\n",
        "\n",
        "def build_mobilenet(n_classes, img_size=IMG_SIZE):\n",
        "    \"\"\"MobileNetV2 (Lightweight Baseline)\"\"\"\n",
        "    base = MobileNetV2(include_top=False, weights='imagenet', input_shape=(img_size, img_size, 3))\n",
        "    base.trainable = True\n",
        "    x = layers.GlobalAveragePooling2D()(base.output)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.4)(x)\n",
        "    x = layers.Dense(256, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(1e-4))(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Dropout(0.3)(x)\n",
        "    out = layers.Dense(n_classes, activation='softmax')(x)\n",
        "    return models.Model(base.input, out, name='MobileNetV2')\n",
        "\n",
        "# Model registry\n",
        "MODELS = {\n",
        "    'EfficientNetB0': (build_efficientnet_vanilla, eff_preprocess),\n",
        "    'EfficientNetB0_SE': (build_efficientnet_se, eff_preprocess),\n",
        "    'EfficientNetB0_CBAM': (build_efficientnet_cbam, eff_preprocess),\n",
        "    'MobileNetV2': (build_mobilenet, mob_preprocess),\n",
        "}\n",
        "\n",
        "# ---------- DATASET LOADER ----------\n",
        "print(\"\\nSetting up dataset...\")\n",
        "possible_paths = [\n",
        "    '/kaggle/input/dental-radiography',\n",
        "    '/kaggle/input/dental-radiography/dataset',\n",
        "    './dental-radiography'\n",
        "]\n",
        "dataset_path = None\n",
        "for p in possible_paths:\n",
        "    if os.path.exists(os.path.join(p, 'train')):\n",
        "        dataset_path = p\n",
        "        print(f\"Found dataset at: {p}\")\n",
        "        break\n",
        "\n",
        "if dataset_path is None:\n",
        "    try:\n",
        "        import kagglehub\n",
        "        dataset_path = kagglehub.dataset_download('imtkaggleteam/dental-radiography')\n",
        "        print(f\"Downloaded dataset to: {dataset_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error downloading dataset: {e}\")\n",
        "        raise\n",
        "\n",
        "# ---------- FOCAL LOSS ----------\n",
        "class FocalLoss(tf.keras.losses.Loss):\n",
        "    def __init__(self, alpha=0.5, gamma=1.0, name='focal_loss'):\n",
        "        super().__init__(name=name)\n",
        "        self.alpha, self.gamma = alpha, gamma\n",
        "\n",
        "    def call(self, y_true, y_pred):\n",
        "        y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7)\n",
        "        ce = -y_true * tf.math.log(y_pred)\n",
        "        weight = self.alpha * y_true * tf.pow(1 - y_pred, self.gamma)\n",
        "        return tf.reduce_sum(weight * ce, axis=-1)\n",
        "\n",
        "# ---------- DATA PIPELINE ----------\n",
        "def load_ann(csv):\n",
        "    \"\"\"Load annotations with outlier filtering\"\"\"\n",
        "    df = pd.read_csv(csv)\n",
        "    df['area'] = (df['xmax']-df['xmin']) * (df['ymax']-df['ymin'])\n",
        "    q25, q75 = df['area'].quantile([0.25, 0.75])\n",
        "    return df[(df['area']>=q25) & (df['area']<=q75)]\n",
        "\n",
        "def load_imgs(df, folder):\n",
        "    \"\"\"Load and preprocess images\"\"\"\n",
        "    imgs, labs = [], []\n",
        "    for _, r in df.iterrows():\n",
        "        path = os.path.join(folder, r['filename'])\n",
        "        if not os.path.exists(path):\n",
        "            continue\n",
        "        img = cv2.imread(path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        g = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "        crop = g[int(r['ymin']):int(r['ymax']), int(r['xmin']):int(r['xmax'])]\n",
        "        if crop.size == 0:\n",
        "            continue\n",
        "        rgb = cv2.cvtColor(cv2.resize(crop, (IMG_SIZE, IMG_SIZE)), cv2.COLOR_GRAY2RGB)\n",
        "        imgs.append(rgb)\n",
        "        labs.append(r['class'])\n",
        "    return np.array(imgs), np.array(labs)\n",
        "\n",
        "print(\"Loading data...\")\n",
        "train_df = load_ann(os.path.join(dataset_path, 'train/_annotations.csv'))\n",
        "valid_df = load_ann(os.path.join(dataset_path, 'valid/_annotations.csv'))\n",
        "test_df  = load_ann(os.path.join(dataset_path, 'test/_annotations.csv'))\n",
        "\n",
        "X_train, y_train = load_imgs(train_df, os.path.join(dataset_path, 'train'))\n",
        "X_valid, y_valid = load_imgs(valid_df, os.path.join(dataset_path, 'valid'))\n",
        "X_test, y_test = load_imgs(test_df, os.path.join(dataset_path, 'test'))\n",
        "\n",
        "print(f\"Train: {len(X_train)} samples\")\n",
        "print(f\"Valid: {len(X_valid)} samples\")\n",
        "print(f\"Test:  {len(X_test)} samples\")\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_train_enc = le.fit_transform(y_train)\n",
        "y_valid_enc = le.transform(y_valid)\n",
        "y_test_enc = le.transform(y_test)\n",
        "\n",
        "y_train_cat = tf.keras.utils.to_categorical(y_train_enc)\n",
        "y_valid_cat = tf.keras.utils.to_categorical(y_valid_enc)\n",
        "y_test_cat = tf.keras.utils.to_categorical(y_test_enc)\n",
        "\n",
        "print(f\"Classes: {le.classes_}\")\n",
        "\n",
        "# CRITICAL: Compute class weights for imbalanced data\n",
        "class_weights = dict(enumerate(\n",
        "    compute_class_weight('balanced', classes=np.unique(y_train_enc), y=y_train_enc)\n",
        "))\n",
        "print(f\"Class weights: {class_weights}\")\n",
        "\n",
        "# ---------- TTA FUNCTION ----------\n",
        "def tta_predict(model, X, steps=TTA_STEPS):\n",
        "    \"\"\"Test-Time Augmentation with mild augmentation (anatomy-aware)\"\"\"\n",
        "    preds = [model.predict(X, verbose=0)]\n",
        "    datagen = ImageDataGenerator(\n",
        "        rotation_range=5,        # Mild rotation\n",
        "        width_shift_range=0.05,  # Small shift\n",
        "        height_shift_range=0.05,\n",
        "        horizontal_flip=False    # No flip for dental X-rays (anatomy matters)\n",
        "    )\n",
        "    for _ in range(steps-1):\n",
        "        aug = next(datagen.flow(X, batch_size=len(X), shuffle=False))\n",
        "        preds.append(model.predict(aug, verbose=0))\n",
        "    return np.mean(preds, axis=0), np.std(preds, axis=0)\n",
        "\n",
        "# ---------- CREATE OUTPUT DIRECTORIES ----------\n",
        "os.makedirs('figures', exist_ok=True)\n",
        "os.makedirs('models', exist_ok=True)\n",
        "\n",
        "# ---------- TRAIN & EVAL LOOP ----------\n",
        "results = {}\n",
        "histories = {}\n",
        "\n",
        "for model_name, (build_fn, preprocess_fn) in MODELS.items():\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"Training {model_name}\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Clear session to free memory\n",
        "    tf.keras.backend.clear_session()\n",
        "\n",
        "    # Build model\n",
        "    model = build_fn(len(le.classes_))\n",
        "    model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(1e-4),\n",
        "        loss=FocalLoss(alpha=0.5, gamma=1.0),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(f\"Model parameters: {model.count_params():,}\")\n",
        "\n",
        "    # Data generators (anatomy-aware augmentation - NO horizontal flip)\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        rotation_range=15,       # Moderate rotation\n",
        "        width_shift_range=0.1,   # Small shift\n",
        "        height_shift_range=0.1,\n",
        "        zoom_range=0.1,         # Small zoom\n",
        "        horizontal_flip=False,   # CRITICAL: No flip for dental anatomy\n",
        "        preprocessing_function=preprocess_fn\n",
        "    )\n",
        "    valid_datagen = ImageDataGenerator(preprocessing_function=preprocess_fn)\n",
        "\n",
        "    train_gen = train_datagen.flow(\n",
        "        X_train.astype('float32'), y_train_cat,\n",
        "        batch_size=BATCH_SIZE, shuffle=True, seed=SEED\n",
        "    )\n",
        "    valid_gen = valid_datagen.flow(\n",
        "        X_valid.astype('float32'), y_valid_cat,\n",
        "        batch_size=BATCH_SIZE, shuffle=False\n",
        "    )\n",
        "\n",
        "    # Callbacks\n",
        "    cb = [\n",
        "        EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1),\n",
        "        ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
        "        ModelCheckpoint(f'models/best_{model_name}.keras', monitor='val_accuracy',\n",
        "                       save_best_only=True, verbose=0)\n",
        "    ]\n",
        "\n",
        "    # Train with class weights (CRITICAL for imbalanced data!)\n",
        "    start_time = time.time()\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        validation_data=valid_gen,\n",
        "        epochs=EPOCHS,\n",
        "        class_weight=class_weights,  # CRITICAL: Handle class imbalance\n",
        "        callbacks=cb,\n",
        "        verbose=1,\n",
        "        steps_per_epoch=len(X_train)//BATCH_SIZE,\n",
        "        validation_steps=len(X_valid)//BATCH_SIZE\n",
        "    )\n",
        "\n",
        "    train_time = time.time() - start_time\n",
        "    histories[model_name] = history.history\n",
        "\n",
        "    # Inference time measurement\n",
        "    X_test_prep = preprocess_fn(X_test.astype('float32'))\n",
        "    start_inf = time.time()\n",
        "    _ = model.predict(X_test_prep[:10], verbose=0)\n",
        "    inf_time = (time.time() - start_inf) / 10 * 1000  # ms per image\n",
        "\n",
        "    params = model.count_params()\n",
        "\n",
        "    # Standard predictions\n",
        "    print(\"\\nRunning standard inference...\")\n",
        "    y_pred_std = model.predict(X_test_prep, verbose=0)\n",
        "    y_pred_std_cls = np.argmax(y_pred_std, axis=1)\n",
        "\n",
        "    # TTA predictions\n",
        "    print(\"Running TTA inference...\")\n",
        "    y_pred_tta, y_pred_tta_var = tta_predict(model, X_test_prep)\n",
        "    y_pred_tta_cls = np.argmax(y_pred_tta, axis=1)\n",
        "\n",
        "    # Compute metrics\n",
        "    acc_std = np.mean(y_test_enc == y_pred_std_cls)\n",
        "    f1_macro_std = f1_score(y_test_enc, y_pred_std_cls, average='macro')\n",
        "    f1_weighted_std = f1_score(y_test_enc, y_pred_std_cls, average='weighted')\n",
        "    mcc_std = matthews_corrcoef(y_test_enc, y_pred_std_cls)\n",
        "\n",
        "    acc_tta = np.mean(y_test_enc == y_pred_tta_cls)\n",
        "    f1_macro_tta = f1_score(y_test_enc, y_pred_tta_cls, average='macro')\n",
        "    f1_weighted_tta = f1_score(y_test_enc, y_pred_tta_cls, average='weighted')\n",
        "    mcc_tta = matthews_corrcoef(y_test_enc, y_pred_tta_cls)\n",
        "\n",
        "    # AUC-ROC\n",
        "    try:\n",
        "        auc_std = roc_auc_score(y_test_cat, y_pred_std, multi_class='ovr', average='macro')\n",
        "        auc_tta = roc_auc_score(y_test_cat, y_pred_tta, multi_class='ovr', average='macro')\n",
        "    except Exception as e:\n",
        "        print(f\"AUC calculation failed: {e}\")\n",
        "        auc_std = 0.0\n",
        "        auc_tta = 0.0\n",
        "\n",
        "    # Confusion matrices\n",
        "    cm_std = confusion_matrix(y_test_enc, y_pred_std_cls)\n",
        "    cm_tta = confusion_matrix(y_test_enc, y_pred_tta_cls)\n",
        "\n",
        "    # Store results\n",
        "    results[model_name] = {\n",
        "        'params': params,\n",
        "        'train_time': train_time,\n",
        "        'inf_time': inf_time,\n",
        "        'std': {\n",
        "            'acc': acc_std,\n",
        "            'f1_macro': f1_macro_std,\n",
        "            'f1_weighted': f1_weighted_std,\n",
        "            'mcc': mcc_std,\n",
        "            'auc': auc_std,\n",
        "            'cm': cm_std\n",
        "        },\n",
        "        'tta': {\n",
        "            'acc': acc_tta,\n",
        "            'f1_macro': f1_macro_tta,\n",
        "            'f1_weighted': f1_weighted_tta,\n",
        "            'mcc': mcc_tta,\n",
        "            'auc': auc_tta,\n",
        "            'cm': cm_tta,\n",
        "            'proba': y_pred_tta,\n",
        "            'var': y_pred_tta_var\n",
        "        },\n",
        "        'predictions': {\n",
        "            'std_cls': y_pred_std_cls,\n",
        "            'tta_cls': y_pred_tta_cls\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # Print results\n",
        "    print(f\"\\n{model_name} Results:\")\n",
        "    print(f\"  Parameters:    {params:,}\")\n",
        "    print(f\"  Train Time:    {train_time:.1f}s ({train_time/60:.1f} min)\")\n",
        "    print(f\"  Inference:     {inf_time:.2f}ms/image\")\n",
        "    print(f\"  Standard:      Acc={acc_std:.4f}, F1={f1_macro_std:.4f}, AUC={auc_std:.4f}\")\n",
        "    print(f\"  TTA:           Acc={acc_tta:.4f}, F1={f1_macro_tta:.4f}, AUC={auc_tta:.4f}\")\n",
        "    print(f\"  Improvement:   +{(acc_tta-acc_std)*100:.2f}% accuracy\")\n",
        "\n",
        "# ---------- ANALYSIS & VISUALIZATION ----------\n",
        "model_names = list(results.keys())\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"GENERATING VISUALIZATIONS AND ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# 1. Confusion Matrices (2x2 grid)\n",
        "print(\"\\n1. Plotting confusion matrices...\")\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.ravel()\n",
        "for i, model_name in enumerate(model_names):\n",
        "    cm = results[model_name]['tta']['cm']\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=le.classes_, yticklabels=le.classes_, ax=axes[i])\n",
        "    axes[i].set_title(f'{model_name} (TTA)', fontsize=12, fontweight='bold')\n",
        "    axes[i].set_xlabel('Predicted', fontsize=10)\n",
        "    axes[i].set_ylabel('True', fontsize=10)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/confusion_matrices.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig('figures/confusion_matrices.pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"   ✓ Saved: confusion_matrices.png/pdf\")\n",
        "\n",
        "# 2. Training Curves\n",
        "print(\"2. Plotting training curves...\")\n",
        "fig = plt.figure(figsize=(14, 10))\n",
        "for i, model_name in enumerate(model_names):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    h = histories[model_name]\n",
        "    epochs_range = range(len(h['accuracy']))\n",
        "    plt.plot(epochs_range, h['accuracy'], 'b-', label='Train Acc', linewidth=2)\n",
        "    plt.plot(epochs_range, h['val_accuracy'], 'r-', label='Val Acc', linewidth=2)\n",
        "    plt.title(f'{model_name}', fontsize=12, fontweight='bold')\n",
        "    plt.xlabel('Epoch', fontsize=10)\n",
        "    plt.ylabel('Accuracy', fontsize=10)\n",
        "    plt.legend(fontsize=9)\n",
        "    plt.grid(alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/training_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig('figures/training_curves.pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"   ✓ Saved: training_curves.png/pdf\")\n",
        "\n",
        "# 3. Model Comparison Bar Charts\n",
        "print(\"3. Plotting model comparisons...\")\n",
        "metrics_to_plot = ['acc', 'f1_macro', 'auc']\n",
        "for metric in metrics_to_plot:\n",
        "    std_vals = [results[m]['std'][metric] for m in model_names]\n",
        "    tta_vals = [results[m]['tta'][metric] for m in model_names]\n",
        "    x = np.arange(len(model_names))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    bars1 = ax.bar(x - width/2, std_vals, width, label='Standard', alpha=0.8)\n",
        "    bars2 = ax.bar(x + width/2, tta_vals, width, label='TTA', alpha=0.8)\n",
        "\n",
        "    ax.set_xlabel('Models', fontsize=12, fontweight='bold')\n",
        "    ax.set_ylabel(metric.upper(), fontsize=12, fontweight='bold')\n",
        "    ax.set_title(f'{metric.upper()} Comparison', fontsize=14, fontweight='bold')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(model_names, rotation=45, ha='right')\n",
        "    ax.legend(fontsize=11)\n",
        "    ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "    # Add value labels\n",
        "    for bars in [bars1, bars2]:\n",
        "        for bar in bars:\n",
        "            height = bar.get_height()\n",
        "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "                   f'{height:.3f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f'figures/comparison_{metric}.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig(f'figures/comparison_{metric}.pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "print(\"   ✓ Saved: comparison_*.png/pdf\")\n",
        "\n",
        "# 4. Select Best Model\n",
        "best_model_name = max(results, key=lambda x: results[x]['tta']['acc'])\n",
        "print(f\"\\n4. Best Model: {best_model_name} (TTA Acc={results[best_model_name]['tta']['acc']:.4f})\")\n",
        "\n",
        "# 5. Per-Class Performance (Best Model)\n",
        "print(\"5. Plotting per-class performance...\")\n",
        "precision, recall, f1_per_class, _ = precision_recall_fscore_support(\n",
        "    y_test_enc, results[best_model_name]['predictions']['tta_cls'], average=None\n",
        ")\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "x = np.arange(len(le.classes_))\n",
        "width = 0.25\n",
        "\n",
        "bars1 = ax.bar(x - width, precision, width, label='Precision', alpha=0.8)\n",
        "bars2 = ax.bar(x, recall, width, label='Recall', alpha=0.8)\n",
        "bars3 = ax.bar(x + width, f1_per_class, width, label='F1-Score', alpha=0.8)\n",
        "\n",
        "ax.set_xlabel('Classes', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('Score', fontsize=12, fontweight='bold')\n",
        "ax.set_title(f'Per-Class Performance - {best_model_name} (TTA)', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(le.classes_, rotation=45, ha='right')\n",
        "ax.legend(fontsize=11)\n",
        "ax.set_ylim([0, 1.1])\n",
        "ax.grid(axis='y', alpha=0.3)\n",
        "\n",
        "for bars in [bars1, bars2, bars3]:\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.text(bar.get_x() + bar.get_width()/2., height,\n",
        "               f'{height:.2f}', ha='center', va='bottom', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/per_class_performance.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig('figures/per_class_performance.pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"   ✓ Saved: per_class_performance.png/pdf\")\n",
        "\n",
        "# 6. ROC Curves (Best Model)\n",
        "print(\"6. Plotting ROC curves...\")\n",
        "y_proba = results[best_model_name]['tta']['proba']\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "colors = ['blue', 'red', 'green', 'orange']\n",
        "for i in range(len(le.classes_)):\n",
        "    fpr, tpr, _ = roc_curve(y_test_cat[:, i], y_proba[:, i])\n",
        "    roc_auc = auc(fpr, tpr)\n",
        "    ax.plot(fpr, tpr, color=colors[i], lw=2,\n",
        "            label=f'{le.classes_[i]} (AUC = {roc_auc:.3f})')\n",
        "\n",
        "ax.plot([0, 1], [0, 1], 'k--', lw=2, label='Random (AUC = 0.5)')\n",
        "ax.set_xlim([0.0, 1.0])\n",
        "ax.set_ylim([0.0, 1.05])\n",
        "ax.set_xlabel('False Positive Rate', fontsize=12, fontweight='bold')\n",
        "ax.set_ylabel('True Positive Rate', fontsize=12, fontweight='bold')\n",
        "ax.set_title(f'ROC Curves - {best_model_name} (TTA)', fontsize=14, fontweight='bold')\n",
        "ax.legend(loc='lower right', fontsize=10)\n",
        "ax.grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/roc_curves.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig('figures/roc_curves.pdf', bbox_inches='tight')\n",
        "plt.close()\n",
        "print(\"   ✓ Saved: roc_curves.png/pdf\")\n",
        "\n",
        "# ---------- STATISTICAL TESTING ----------\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"STATISTICAL TESTING\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# McNemar's Test\n",
        "print(\"\\nMcNemar's Test (Pairwise Model Comparison):\")\n",
        "mcnemar_results = {}\n",
        "for i in range(len(model_names)):\n",
        "    for j in range(i+1, len(model_names)):\n",
        "        m1, m2 = model_names[i], model_names[j]\n",
        "        y1 = results[m1]['predictions']['tta_cls']\n",
        "        y2 = results[m2]['predictions']['tta_cls']\n",
        "        y1_correct = (y1 == y_test_enc)\n",
        "        y2_correct = (y2 == y_test_enc)\n",
        "\n",
        "        n_01 = np.sum(~y1_correct & y2_correct)\n",
        "        n_10 = np.sum(y1_correct & ~y2_correct)\n",
        "        table = [[0, n_01], [n_10, 0]]\n",
        "\n",
        "        mc_test = mcnemar(table, exact=False, correction=True)\n",
        "        mcnemar_results[f\"{m1} vs {m2}\"] = {\n",
        "            'statistic': mc_test.statistic,\n",
        "            'p_value': mc_test.pvalue\n",
        "        }\n",
        "        sig = \"✓ Significant\" if mc_test.pvalue < 0.05 else \"✗ Not significant\"\n",
        "        print(f\"  {m1} vs {m2}: p={mc_test.pvalue:.4f} ({sig})\")\n",
        "\n",
        "# Wilcoxon Test (Standard vs TTA)\n",
        "print(\"\\nWilcoxon Test (Standard vs TTA):\")\n",
        "wilcoxon_results = {}\n",
        "for model_name in model_names:\n",
        "    std_correct = (results[model_name]['predictions']['std_cls'] == y_test_enc).astype(int)\n",
        "    tta_correct = (results[model_name]['predictions']['tta_cls'] == y_test_enc).astype(int)\n",
        "\n",
        "    try:\n",
        "        wilcox_test = wilcoxon(std_correct, tta_correct)\n",
        "        wilcoxon_results[model_name] = {\n",
        "            'statistic': wilcox_test.statistic,\n",
        "            'p_value': wilcox_test.pvalue\n",
        "        }\n",
        "        sig = \"✓ Significant\" if wilcox_test.pvalue < 0.05 else \"✗ Not significant\"\n",
        "        print(f\"  {model_name}: p={wilcox_test.pvalue:.4f} ({sig})\")\n",
        "    except Exception as e:\n",
        "        print(f\"  {model_name}: Test failed ({e})\")\n",
        "\n",
        "# 95% Confidence Intervals\n",
        "print(\"\\n95% Confidence Intervals:\")\n",
        "def confidence_interval(p, n, alpha=0.05):\n",
        "    z = norm.ppf(1 - alpha/2)\n",
        "    se = np.sqrt(p * (1 - p) / n)\n",
        "    return p - z * se, p + z * se\n",
        "\n",
        "n = len(y_test_enc)\n",
        "ci_results = {}\n",
        "for model_name in model_names:\n",
        "    acc_std = results[model_name]['std']['acc']\n",
        "    acc_tta = results[model_name]['tta']['acc']\n",
        "    ci_std = confidence_interval(acc_std, n)\n",
        "    ci_tta = confidence_interval(acc_tta, n)\n",
        "    ci_results[model_name] = {'std_ci': ci_std, 'tta_ci': ci_tta}\n",
        "    print(f\"  {model_name}:\")\n",
        "    print(f\"    Standard: [{ci_std[0]:.4f}, {ci_std[1]:.4f}]\")\n",
        "    print(f\"    TTA:      [{ci_tta[0]:.4f}, {ci_tta[1]:.4f}]\")\n",
        "\n",
        "# ---------- GRAD-CAM VISUALIZATION ----------\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"GRAD-CAM VISUALIZATION\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    \"\"\"Generate Grad-CAM heatmap\"\"\"\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.maximum(tf.reduce_max(heatmap), 1e-10)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "def superimpose_heatmap(img, heatmap, alpha=0.4):\n",
        "    \"\"\"Overlay heatmap on image\"\"\"\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    jet = plt.cm.get_cmap(\"jet\")\n",
        "    jet_colors = jet(np.arange(256))[:, :3]\n",
        "    jet_heatmap = jet_colors[heatmap]\n",
        "    jet_heatmap = tf.keras.preprocessing.image.array_to_img(jet_heatmap)\n",
        "    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n",
        "    jet_heatmap = tf.keras.preprocessing.image.img_to_array(jet_heatmap)\n",
        "    superimposed_img = jet_heatmap * alpha + img\n",
        "    superimposed_img = tf.keras.preprocessing.image.array_to_img(superimposed_img)\n",
        "    return superimposed_img\n",
        "\n",
        "print(f\"Generating Grad-CAM for {best_model_name}...\")\n",
        "try:\n",
        "    # Load best model\n",
        "    best_model_fn = MODELS[best_model_name][0]\n",
        "    best_preprocess = MODELS[best_model_name][1]\n",
        "\n",
        "    viz_model = best_model_fn(len(le.classes_))\n",
        "    viz_model.load_weights(f'models/best_{best_model_name}.keras')\n",
        "\n",
        "    # Auto-find last conv layer\n",
        "    target_layer = None\n",
        "    for layer in reversed(viz_model.layers):\n",
        "        if 'conv' in layer.name.lower() or 'relu' in layer.name.lower():\n",
        "            target_layer = layer.name\n",
        "            break\n",
        "\n",
        "    if target_layer is None:\n",
        "        print(\"  Warning: Could not find convolutional layer\")\n",
        "        target_layer = viz_model.layers[-10].name  # Fallback\n",
        "\n",
        "    print(f\"  Using layer: {target_layer}\")\n",
        "\n",
        "    # Generate visualizations (one per class)\n",
        "    fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
        "    for i, cls in enumerate(le.classes_):\n",
        "        class_indices = np.where(y_test_enc == i)[0]\n",
        "        if len(class_indices) > 0:\n",
        "            idx = class_indices[0]\n",
        "            img = X_test[idx]\n",
        "            img_prep = best_preprocess(np.expand_dims(img.astype('float32'), axis=0))\n",
        "\n",
        "            heatmap = make_gradcam_heatmap(img_prep, viz_model, target_layer)\n",
        "            viz = superimpose_heatmap(img, heatmap)\n",
        "\n",
        "            axes[i].imshow(viz)\n",
        "            pred_cls = results[best_model_name]['predictions']['tta_cls'][idx]\n",
        "            axes[i].set_title(f'True: {cls}\\nPred: {le.classes_[pred_cls]}', fontsize=10)\n",
        "            axes[i].axis('off')\n",
        "        else:\n",
        "            axes[i].axis('off')\n",
        "            axes[i].set_title(f'{cls}\\n(No samples)', fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('figures/gradcam.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig('figures/gradcam.pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"   ✓ Saved: gradcam.png/pdf\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  Grad-CAM generation failed: {e}\")\n",
        "\n",
        "# ---------- TTA ABLATION STUDY ----------\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"TTA ABLATION STUDY\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(f\"Running ablation on {best_model_name}...\")\n",
        "try:\n",
        "    # Load best model fresh\n",
        "    ablation_model = MODELS[best_model_name][0](len(le.classes_))\n",
        "    ablation_model.load_weights(f'models/best_{best_model_name}.keras')\n",
        "    X_test_prep = MODELS[best_model_name][1](X_test.astype('float32'))\n",
        "\n",
        "    steps_list = [3, 6, 10, 15]\n",
        "    accs = []\n",
        "    f1s = []\n",
        "\n",
        "    for steps in steps_list:\n",
        "        print(f\"  Testing {steps} TTA steps...\")\n",
        "        y_p, _ = tta_predict(ablation_model, X_test_prep, steps=steps)\n",
        "        y_p_cls = np.argmax(y_p, axis=1)\n",
        "        acc = np.mean(y_test_enc == y_p_cls)\n",
        "        f1 = f1_score(y_test_enc, y_p_cls, average='macro')\n",
        "        accs.append(acc)\n",
        "        f1s.append(f1)\n",
        "        print(f\"    Acc={acc:.4f}, F1={f1:.4f}\")\n",
        "\n",
        "    # Plot\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "    ax1.plot(steps_list, accs, marker='o', linewidth=2, markersize=8)\n",
        "    ax1.set_xlabel('TTA Steps', fontsize=12, fontweight='bold')\n",
        "    ax1.set_ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
        "    ax1.set_title(f'TTA Steps vs Accuracy\\n({best_model_name})', fontsize=14, fontweight='bold')\n",
        "    ax1.grid(alpha=0.3)\n",
        "\n",
        "    ax2.plot(steps_list, f1s, marker='s', linewidth=2, markersize=8, color='red')\n",
        "    ax2.set_xlabel('TTA Steps', fontsize=12, fontweight='bold')\n",
        "    ax2.set_ylabel('Macro-F1', fontsize=12, fontweight='bold')\n",
        "    ax2.set_title(f'TTA Steps vs Macro-F1\\n({best_model_name})', fontsize=14, fontweight='bold')\n",
        "    ax2.grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('figures/tta_ablation.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig('figures/tta_ablation.pdf', bbox_inches='tight')\n",
        "    plt.close()\n",
        "    print(\"   ✓ Saved: tta_ablation.png/pdf\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"  TTA ablation failed: {e}\")\n",
        "\n",
        "# ---------- FAILURE ANALYSIS ----------\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"FAILURE ANALYSIS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "print(\"\\nMisclassification counts:\")\n",
        "for model_name in model_names:\n",
        "    pred = results[model_name]['predictions']['tta_cls']\n",
        "    mis_count = np.sum(pred != y_test_enc)\n",
        "    print(f\"  {model_name}: {mis_count} errors ({mis_count/len(y_test_enc)*100:.1f}%)\")\n",
        "\n",
        "print(\"\\nMost common errors (True → Pred):\")\n",
        "all_errors = []\n",
        "for model_name in model_names:\n",
        "    pred = results[model_name]['predictions']['tta_cls']\n",
        "    for i in range(len(y_test_enc)):\n",
        "        if pred[i] != y_test_enc[i]:\n",
        "            all_errors.append((y_test_enc[i], pred[i]))\n",
        "\n",
        "error_counts = Counter(all_errors)\n",
        "for (true, pred), count in error_counts.most_common(10):\n",
        "    print(f\"  {le.classes_[true]} → {le.classes_[pred]}: {count} times\")\n",
        "\n",
        "# ---------- LATEX TABLES ----------\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"LATEX TABLES FOR PAPER\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Dataset Statistics\n",
        "train_counts = pd.Series(y_train).value_counts().sort_index()\n",
        "val_counts = pd.Series(y_valid).value_counts().sort_index()\n",
        "test_counts = pd.Series(y_test).value_counts().sort_index()\n",
        "\n",
        "print(\"\\n--- Dataset Statistics Table ---\")\n",
        "print(\"\\\\begin{table}[htbp]\")\n",
        "print(\"\\\\centering\")\n",
        "print(\"\\\\caption{Dataset Statistics}\")\n",
        "print(\"\\\\begin{tabular}{|l|r|r|r|r|}\")\n",
        "print(\"\\\\hline\")\n",
        "print(\"\\\\textbf{Class} & \\\\textbf{Train} & \\\\textbf{Val} & \\\\textbf{Test} & \\\\textbf{Total} \\\\\\\\ \\\\hline\")\n",
        "for i, cls in enumerate(le.classes_):\n",
        "    cls_total = train_counts.get(i, 0) + val_counts.get(i, 0) + test_counts.get(i, 0)\n",
        "    print(f\"{cls} & {train_counts.get(i, 0)} & {val_counts.get(i, 0)} & {test_counts.get(i, 0)} & {cls_total} \\\\\\\\ \\\\hline\")\n",
        "print(f\"\\\\textbf{{Total}} & {len(X_train)} & {len(X_valid)} & {len(X_test)} & {len(X_train)+len(X_valid)+len(X_test)} \\\\\\\\ \\\\hline\")\n",
        "print(\"\\\\end{tabular}\")\n",
        "print(\"\\\\end{table}\")\n",
        "\n",
        "# Model Comparison\n",
        "print(\"\\n--- Model Comparison Table ---\")\n",
        "print(\"\\\\begin{table*}[htbp]\")\n",
        "print(\"\\\\centering\")\n",
        "print(\"\\\\caption{Model Performance Comparison}\")\n",
        "print(\"\\\\begin{tabular}{|l|r|r|c|c|c|c|}\")\n",
        "print(\"\\\\hline\")\n",
        "print(\"\\\\textbf{Model} & \\\\textbf{Params} & \\\\textbf{Inf (ms)} & \\\\textbf{Std Acc} & \\\\textbf{TTA Acc} & \\\\textbf{TTA F1} & \\\\textbf{AUC} \\\\\\\\ \\\\hline\")\n",
        "for model_name in model_names:\n",
        "    res = results[model_name]\n",
        "    params_str = f\"{res['params']:,}\"\n",
        "    print(f\"{model_name.replace('_', ' ')} & {params_str} & {res['inf_time']:.1f} & {res['std']['acc']:.4f} & {res['tta']['acc']:.4f} & {res['tta']['f1_macro']:.4f} & {res['tta']['auc']:.4f} \\\\\\\\ \\\\hline\")\n",
        "print(\"\\\\end{tabular}\")\n",
        "print(\"\\\\end{table*}\")\n",
        "\n",
        "# Per-Class Metrics\n",
        "print(\"\\n--- Per-Class Metrics Table ---\")\n",
        "print(\"\\\\begin{table}[htbp]\")\n",
        "print(\"\\\\centering\")\n",
        "print(\"\\\\caption{Per-Class Performance (\" + best_model_name.replace('_', ' ') + \")}\")\n",
        "print(\"\\\\begin{tabular}{|l|c|c|c|}\")\n",
        "print(\"\\\\hline\")\n",
        "print(\"\\\\textbf{Class} & \\\\textbf{Precision} & \\\\textbf{Recall} & \\\\textbf{F1-Score} \\\\\\\\ \\\\hline\")\n",
        "for i, cls in enumerate(le.classes_):\n",
        "    print(f\"{cls} & {precision[i]:.4f} & {recall[i]:.4f} & {f1_per_class[i]:.4f} \\\\\\\\ \\\\hline\")\n",
        "print(\"\\\\end{tabular}\")\n",
        "print(\"\\\\end{table}\")\n",
        "\n",
        "# Attention Ablation\n",
        "attention_models = ['EfficientNetB0', 'EfficientNetB0_SE', 'EfficientNetB0_CBAM']\n",
        "print(\"\\n--- Attention Ablation Table ---\")\n",
        "print(\"\\\\begin{table}[htbp]\")\n",
        "print(\"\\\\centering\")\n",
        "print(\"\\\\caption{Attention Mechanism Ablation}\")\n",
        "print(\"\\\\begin{tabular}{|l|c|c|c|}\")\n",
        "print(\"\\\\hline\")\n",
        "print(\"\\\\textbf{Model} & \\\\textbf{TTA Acc} & \\\\textbf{Macro-F1} & \\\\textbf{AUC} \\\\\\\\ \\\\hline\")\n",
        "for model in attention_models:\n",
        "    if model in results:\n",
        "        res = results[model]['tta']\n",
        "        print(f\"{model.replace('_', ' ')} & {res['acc']:.4f} & {res['f1_macro']:.4f} & {res['auc']:.4f} \\\\\\\\ \\\\hline\")\n",
        "print(\"\\\\end{tabular}\")\n",
        "print(\"\\\\end{table}\")\n",
        "\n",
        "# ---------- SAVE RESULTS ----------\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"SAVING RESULTS\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# Save JSON\n",
        "results_for_json = {}\n",
        "for model_name, res in results.items():\n",
        "    results_for_json[model_name] = {\n",
        "        'params': int(res['params']),\n",
        "        'train_time': float(res['train_time']),\n",
        "        'inf_time': float(res['inf_time']),\n",
        "        'std': {k: float(v) if not isinstance(v, np.ndarray) else v.tolist()\n",
        "                for k, v in res['std'].items()},\n",
        "        'tta': {k: float(v) if not isinstance(v, np.ndarray) else v.tolist()\n",
        "                for k, v in res['tta'].items()}\n",
        "    }\n",
        "\n",
        "with open('results.json', 'w') as f:\n",
        "    json.dump(results_for_json, f, indent=2)\n",
        "print(\"   ✓ Saved: results.json\")\n",
        "\n",
        "# Summary\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(\"EXPERIMENT COMPLETE!\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"\\nBest Model: {best_model_name}\")\n",
        "print(f\"  TTA Accuracy: {results[best_model_name]['tta']['acc']:.4f}\")\n",
        "print(f\"  TTA Macro-F1: {results[best_model_name]['tta']['f1_macro']:.4f}\")\n",
        "print(f\"  TTA AUC:      {results[best_model_name]['tta']['auc']:.4f}\")\n",
        "\n",
        "print(\"\\nGenerated Files:\")\n",
        "print(\"  Models:  models/best_*.keras (4 files)\")\n",
        "print(\"  Figures: figures/*.png & *.pdf (10 files)\")\n",
        "print(\"  Data:    results.json\")\n",
        "\n",
        "print(\"\\n✓ All analyses completed successfully!\")"
      ],
      "metadata": {
        "_uuid": "a21527c4-d837-4d43-b0d9-f5043e22f650",
        "_cell_guid": "8e7136d5-e867-4960-87ab-039c618bb2d4",
        "trusted": true,
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2025-12-28T19:33:02.163026Z",
          "iopub.execute_input": "2025-12-28T19:33:02.163666Z",
          "iopub.status.idle": "2025-12-28T20:33:18.886128Z",
          "shell.execute_reply.started": "2025-12-28T19:33:02.163633Z",
          "shell.execute_reply": "2025-12-28T20:33:18.885487Z"
        },
        "id": "TJZjIzQnr5ZB",
        "outputId": "23a81f93-04b8-405d-91bf-33cc878c109f"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1766950385.675236      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1766950385.730941      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1766950386.173260      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766950386.173309      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766950386.173312      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1766950386.173314      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "TensorFlow Version: 2.19.0\nGPU Available: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n\nSetting up dataset...\nFound dataset at: /kaggle/input/dental-radiography\nLoading data...\nTrain: 4023 samples\nValid: 392 samples\nTest:  237 samples\nClasses: ['Cavity' 'Fillings' 'Impacted Tooth' 'Implant']\nClass weights: {0: np.float64(5.184278350515464), 1: np.float64(0.3822690992018244), 2: np.float64(3.444349315068493), 3: np.float64(1.1100993377483444)}\n\n======================================================================\nTraining EfficientNetB0\n======================================================================\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "I0000 00:00:1766950417.455670      55 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb0_notop.h5\n\u001b[1m16705208/16705208\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nModel parameters: 4,384,679\nEpoch 1/50\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1766950454.080289     125 service.cc:152] XLA service 0x7c6068004230 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1766950454.080337     125 service.cc:160]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\nI0000 00:00:1766950459.956711     125 cuda_dnn.cc:529] Loaded cuDNN version 91002\nI0000 00:00:1766950495.635020     125 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 671ms/step - accuracy: 0.3321 - loss: 0.7050 - val_accuracy: 0.1953 - val_loss: 0.9066 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.4688 - loss: 0.4560 - val_accuracy: 0.1979 - val_loss: 0.9086 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 298ms/step - accuracy: 0.5537 - loss: 0.3525 - val_accuracy: 0.2943 - val_loss: 0.6367 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7188 - loss: 0.2977 - val_accuracy: 0.2917 - val_loss: 0.6342 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 301ms/step - accuracy: 0.6634 - loss: 0.2804 - val_accuracy: 0.8255 - val_loss: 0.2054 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.7812 - loss: 0.1946 - val_accuracy: 0.8359 - val_loss: 0.2049 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 300ms/step - accuracy: 0.7691 - loss: 0.1979 - val_accuracy: 0.8620 - val_loss: 0.1722 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8438 - loss: 0.3998 - val_accuracy: 0.8698 - val_loss: 0.1704 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 302ms/step - accuracy: 0.8293 - loss: 0.1560 - val_accuracy: 0.8724 - val_loss: 0.1678 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7812 - loss: 0.1384 - val_accuracy: 0.8750 - val_loss: 0.1669 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 301ms/step - accuracy: 0.8412 - loss: 0.1563 - val_accuracy: 0.8958 - val_loss: 0.1622 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.1344 - val_accuracy: 0.8932 - val_loss: 0.1622 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 293ms/step - accuracy: 0.8690 - loss: 0.1256 - val_accuracy: 0.8854 - val_loss: 0.1636 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.1199 - val_accuracy: 0.8828 - val_loss: 0.1635 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.8863 - loss: 0.1208\nEpoch 15: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 289ms/step - accuracy: 0.8863 - loss: 0.1208 - val_accuracy: 0.8620 - val_loss: 0.1950 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0635 - val_accuracy: 0.8620 - val_loss: 0.1949 - learning_rate: 5.0000e-05\nEpoch 17/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.9126 - loss: 0.0987 - val_accuracy: 0.8828 - val_loss: 0.1625 - learning_rate: 5.0000e-05\nEpoch 18/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0832 - val_accuracy: 0.8828 - val_loss: 0.1625 - learning_rate: 5.0000e-05\nEpoch 19/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9238 - loss: 0.0992\nEpoch 19: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.9237 - loss: 0.0992 - val_accuracy: 0.8828 - val_loss: 0.1630 - learning_rate: 5.0000e-05\nEpoch 20/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.0792 - val_accuracy: 0.8854 - val_loss: 0.1630 - learning_rate: 2.5000e-05\nEpoch 21/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 298ms/step - accuracy: 0.9208 - loss: 0.1007 - val_accuracy: 0.8984 - val_loss: 0.1545 - learning_rate: 2.5000e-05\nEpoch 22/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0481 - val_accuracy: 0.8984 - val_loss: 0.1547 - learning_rate: 2.5000e-05\nEpoch 23/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 297ms/step - accuracy: 0.9308 - loss: 0.0938 - val_accuracy: 0.9141 - val_loss: 0.1449 - learning_rate: 2.5000e-05\nEpoch 24/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.0934 - val_accuracy: 0.9141 - val_loss: 0.1444 - learning_rate: 2.5000e-05\nEpoch 25/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 297ms/step - accuracy: 0.9281 - loss: 0.0863 - val_accuracy: 0.9297 - val_loss: 0.1374 - learning_rate: 2.5000e-05\nEpoch 26/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.0640 - val_accuracy: 0.9297 - val_loss: 0.1369 - learning_rate: 2.5000e-05\nEpoch 27/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.9297 - loss: 0.0866 - val_accuracy: 0.9089 - val_loss: 0.1453 - learning_rate: 2.5000e-05\nEpoch 28/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.0808 - val_accuracy: 0.9089 - val_loss: 0.1450 - learning_rate: 2.5000e-05\nEpoch 29/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.9186 - loss: 0.0899 - val_accuracy: 0.9219 - val_loss: 0.1439 - learning_rate: 2.5000e-05\nEpoch 30/50\n\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m12s\u001b[0m 105ms/step - accuracy: 1.0000 - loss: 0.0513\nEpoch 30: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0513 - val_accuracy: 0.9219 - val_loss: 0.1433 - learning_rate: 2.5000e-05\nEpoch 31/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 289ms/step - accuracy: 0.9354 - loss: 0.0928 - val_accuracy: 0.9219 - val_loss: 0.1384 - learning_rate: 1.2500e-05\nEpoch 32/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.1279 - val_accuracy: 0.9219 - val_loss: 0.1382 - learning_rate: 1.2500e-05\nEpoch 33/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 289ms/step - accuracy: 0.9480 - loss: 0.0763 - val_accuracy: 0.9193 - val_loss: 0.1421 - learning_rate: 1.2500e-05\nEpoch 34/50\n\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 106ms/step - accuracy: 0.9375 - loss: 0.0999\nEpoch 34: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0999 - val_accuracy: 0.9219 - val_loss: 0.1417 - learning_rate: 1.2500e-05\nEpoch 35/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.9348 - loss: 0.0834 - val_accuracy: 0.9219 - val_loss: 0.1381 - learning_rate: 6.2500e-06\nEpoch 36/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0886 - val_accuracy: 0.9219 - val_loss: 0.1383 - learning_rate: 6.2500e-06\nEpoch 36: early stopping\nRestoring model weights from the end of the best epoch: 26.\n\nRunning standard inference...\nRunning TTA inference...\n\nEfficientNetB0 Results:\n  Parameters:    4,384,679\n  Train Time:    800.8s (13.3 min)\n  Inference:     801.30ms/image\n  Standard:      Acc=0.8987, F1=0.8108, AUC=0.9840\n  TTA:           Acc=0.9325, F1=0.8531, AUC=0.9893\n  Improvement:   +3.38% accuracy\n\n======================================================================\nTraining EfficientNetB0_SE\n======================================================================\nModel parameters: 4,590,839\nEpoch 1/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 618ms/step - accuracy: 0.3495 - loss: 0.6905 - val_accuracy: 0.1615 - val_loss: 0.8075 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3750 - loss: 0.7946 - val_accuracy: 0.1615 - val_loss: 0.8081 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 303ms/step - accuracy: 0.5625 - loss: 0.3507 - val_accuracy: 0.4062 - val_loss: 0.5001 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7812 - loss: 0.1453 - val_accuracy: 0.4115 - val_loss: 0.4946 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 301ms/step - accuracy: 0.7122 - loss: 0.2362 - val_accuracy: 0.7630 - val_loss: 0.2686 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8750 - loss: 0.1793 - val_accuracy: 0.7656 - val_loss: 0.2661 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 300ms/step - accuracy: 0.7855 - loss: 0.1933 - val_accuracy: 0.8490 - val_loss: 0.1803 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.1139 - val_accuracy: 0.8490 - val_loss: 0.1781 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 299ms/step - accuracy: 0.8192 - loss: 0.1737 - val_accuracy: 0.8828 - val_loss: 0.1696 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.0760 - val_accuracy: 0.8854 - val_loss: 0.1679 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 298ms/step - accuracy: 0.8449 - loss: 0.1545 - val_accuracy: 0.8880 - val_loss: 0.1779 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0608 - val_accuracy: 0.8880 - val_loss: 0.1768 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 291ms/step - accuracy: 0.8825 - loss: 0.1368 - val_accuracy: 0.8047 - val_loss: 0.2158 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 112ms/step - accuracy: 0.8438 - loss: 0.1144\nEpoch 14: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.1144 - val_accuracy: 0.8125 - val_loss: 0.2128 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.8965 - loss: 0.1059 - val_accuracy: 0.8464 - val_loss: 0.1849 - learning_rate: 5.0000e-05\nEpoch 16/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.1374 - val_accuracy: 0.8464 - val_loss: 0.1846 - learning_rate: 5.0000e-05\nEpoch 17/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 304ms/step - accuracy: 0.9062 - loss: 0.1012 - val_accuracy: 0.9141 - val_loss: 0.1476 - learning_rate: 5.0000e-05\nEpoch 18/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.1460 - val_accuracy: 0.9115 - val_loss: 0.1492 - learning_rate: 5.0000e-05\nEpoch 19/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 293ms/step - accuracy: 0.9124 - loss: 0.0975 - val_accuracy: 0.8828 - val_loss: 0.1777 - learning_rate: 5.0000e-05\nEpoch 20/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.1782 - val_accuracy: 0.8828 - val_loss: 0.1780 - learning_rate: 5.0000e-05\nEpoch 21/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 290ms/step - accuracy: 0.9118 - loss: 0.1023\nEpoch 21: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 294ms/step - accuracy: 0.9118 - loss: 0.1022 - val_accuracy: 0.9141 - val_loss: 0.1512 - learning_rate: 5.0000e-05\nEpoch 22/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.0718 - val_accuracy: 0.9141 - val_loss: 0.1511 - learning_rate: 2.5000e-05\nEpoch 23/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.9252 - loss: 0.0880 - val_accuracy: 0.9141 - val_loss: 0.1502 - learning_rate: 2.5000e-05\nEpoch 24/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.1406 - val_accuracy: 0.9089 - val_loss: 0.1503 - learning_rate: 2.5000e-05\nEpoch 25/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 303ms/step - accuracy: 0.9326 - loss: 0.0853 - val_accuracy: 0.9167 - val_loss: 0.1440 - learning_rate: 2.5000e-05\nEpoch 26/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.3512 - val_accuracy: 0.9167 - val_loss: 0.1443 - learning_rate: 2.5000e-05\nEpoch 27/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 291ms/step - accuracy: 0.9242 - loss: 0.0922 - val_accuracy: 0.9115 - val_loss: 0.1602 - learning_rate: 2.5000e-05\nEpoch 28/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0671 - val_accuracy: 0.9089 - val_loss: 0.1611 - learning_rate: 2.5000e-05\nEpoch 29/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 301ms/step - accuracy: 0.9434 - loss: 0.0819 - val_accuracy: 0.9271 - val_loss: 0.1341 - learning_rate: 2.5000e-05\nEpoch 30/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.0810 - val_accuracy: 0.9271 - val_loss: 0.1340 - learning_rate: 2.5000e-05\nEpoch 31/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 301ms/step - accuracy: 0.9440 - loss: 0.0744 - val_accuracy: 0.9323 - val_loss: 0.1303 - learning_rate: 2.5000e-05\nEpoch 32/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 0.0539 - val_accuracy: 0.9323 - val_loss: 0.1305 - learning_rate: 2.5000e-05\nEpoch 33/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 294ms/step - accuracy: 0.9507 - loss: 0.0787 - val_accuracy: 0.9271 - val_loss: 0.1358 - learning_rate: 2.5000e-05\nEpoch 34/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.0795 - val_accuracy: 0.9271 - val_loss: 0.1362 - learning_rate: 2.5000e-05\nEpoch 35/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 299ms/step - accuracy: 0.9406 - loss: 0.0782 - val_accuracy: 0.9427 - val_loss: 0.1254 - learning_rate: 2.5000e-05\nEpoch 36/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 1.0000 - loss: 0.0562 - val_accuracy: 0.9401 - val_loss: 0.1250 - learning_rate: 2.5000e-05\nEpoch 37/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 302ms/step - accuracy: 0.9376 - loss: 0.0832 - val_accuracy: 0.9297 - val_loss: 0.1380 - learning_rate: 2.5000e-05\nEpoch 38/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0503 - val_accuracy: 0.9349 - val_loss: 0.1382 - learning_rate: 2.5000e-05\nEpoch 39/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 303ms/step - accuracy: 0.9394 - loss: 0.0887 - val_accuracy: 0.9323 - val_loss: 0.1391 - learning_rate: 2.5000e-05\nEpoch 40/50\n\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - accuracy: 0.9688 - loss: 0.0611\nEpoch 40: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0611 - val_accuracy: 0.9323 - val_loss: 0.1393 - learning_rate: 2.5000e-05\nEpoch 41/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 301ms/step - accuracy: 0.9472 - loss: 0.0747 - val_accuracy: 0.9375 - val_loss: 0.1314 - learning_rate: 1.2500e-05\nEpoch 42/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0758 - val_accuracy: 0.9401 - val_loss: 0.1309 - learning_rate: 1.2500e-05\nEpoch 43/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.9494 - loss: 0.0708 - val_accuracy: 0.9349 - val_loss: 0.1366 - learning_rate: 1.2500e-05\nEpoch 44/50\n\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 107ms/step - accuracy: 0.9375 - loss: 0.0619\nEpoch 44: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0619 - val_accuracy: 0.9349 - val_loss: 0.1371 - learning_rate: 1.2500e-05\nEpoch 45/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 296ms/step - accuracy: 0.9389 - loss: 0.0821 - val_accuracy: 0.9375 - val_loss: 0.1369 - learning_rate: 6.2500e-06\nEpoch 46/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0529 - val_accuracy: 0.9349 - val_loss: 0.1363 - learning_rate: 6.2500e-06\nEpoch 46: early stopping\nRestoring model weights from the end of the best epoch: 36.\n\nRunning standard inference...\nRunning TTA inference...\n\nEfficientNetB0_SE Results:\n  Parameters:    4,590,839\n  Train Time:    980.9s (16.3 min)\n  Inference:     725.33ms/image\n  Standard:      Acc=0.9283, F1=0.8578, AUC=0.9815\n  TTA:           Acc=0.9494, F1=0.8982, AUC=0.9812\n  Improvement:   +2.11% accuracy\n\n======================================================================\nTraining EfficientNetB0_CBAM\n======================================================================\nModel parameters: 4,590,938\nEpoch 1/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 618ms/step - accuracy: 0.2657 - loss: 0.8395 - val_accuracy: 0.2109 - val_loss: 0.5625 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3125 - loss: 0.7264 - val_accuracy: 0.2109 - val_loss: 0.5624 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 307ms/step - accuracy: 0.3739 - loss: 0.5534 - val_accuracy: 0.2214 - val_loss: 0.5480 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3438 - loss: 0.6026 - val_accuracy: 0.2214 - val_loss: 0.5477 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 297ms/step - accuracy: 0.4261 - loss: 0.4537 - val_accuracy: 0.5391 - val_loss: 0.4342 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5000 - loss: 0.3705 - val_accuracy: 0.5417 - val_loss: 0.4333 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 297ms/step - accuracy: 0.5200 - loss: 0.3616 - val_accuracy: 0.6823 - val_loss: 0.3214 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.5312 - loss: 0.3053 - val_accuracy: 0.6823 - val_loss: 0.3203 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 298ms/step - accuracy: 0.5867 - loss: 0.3203 - val_accuracy: 0.7943 - val_loss: 0.2461 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6875 - loss: 0.3796 - val_accuracy: 0.7969 - val_loss: 0.2443 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 292ms/step - accuracy: 0.6733 - loss: 0.2568 - val_accuracy: 0.8125 - val_loss: 0.2583 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8125 - loss: 0.4384 - val_accuracy: 0.8073 - val_loss: 0.2566 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 296ms/step - accuracy: 0.7235 - loss: 0.2254 - val_accuracy: 0.8724 - val_loss: 0.2049 - learning_rate: 1.0000e-04\nEpoch 14/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.5938 - loss: 0.2181 - val_accuracy: 0.8776 - val_loss: 0.2047 - learning_rate: 1.0000e-04\nEpoch 15/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 286ms/step - accuracy: 0.7790 - loss: 0.2015 - val_accuracy: 0.8255 - val_loss: 0.2626 - learning_rate: 1.0000e-04\nEpoch 16/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.1601 - val_accuracy: 0.8255 - val_loss: 0.2636 - learning_rate: 1.0000e-04\nEpoch 17/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 297ms/step - accuracy: 0.8164 - loss: 0.1798 - val_accuracy: 0.9115 - val_loss: 0.1702 - learning_rate: 1.0000e-04\nEpoch 18/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.0837 - val_accuracy: 0.9115 - val_loss: 0.1698 - learning_rate: 1.0000e-04\nEpoch 19/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 298ms/step - accuracy: 0.8330 - loss: 0.1549 - val_accuracy: 0.9193 - val_loss: 0.1681 - learning_rate: 1.0000e-04\nEpoch 20/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.0793 - val_accuracy: 0.9193 - val_loss: 0.1668 - learning_rate: 1.0000e-04\nEpoch 21/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 294ms/step - accuracy: 0.8547 - loss: 0.1465 - val_accuracy: 0.9219 - val_loss: 0.1715 - learning_rate: 1.0000e-04\nEpoch 22/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.1242 - val_accuracy: 0.9193 - val_loss: 0.1715 - learning_rate: 1.0000e-04\nEpoch 23/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 296ms/step - accuracy: 0.8849 - loss: 0.1159 - val_accuracy: 0.9271 - val_loss: 0.1590 - learning_rate: 1.0000e-04\nEpoch 24/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.1675 - val_accuracy: 0.9271 - val_loss: 0.1590 - learning_rate: 1.0000e-04\nEpoch 25/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 291ms/step - accuracy: 0.8933 - loss: 0.1186 - val_accuracy: 0.9271 - val_loss: 0.1523 - learning_rate: 1.0000e-04\nEpoch 26/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9062 - loss: 0.1073 - val_accuracy: 0.9271 - val_loss: 0.1515 - learning_rate: 1.0000e-04\nEpoch 27/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 297ms/step - accuracy: 0.9105 - loss: 0.1234 - val_accuracy: 0.9375 - val_loss: 0.1425 - learning_rate: 1.0000e-04\nEpoch 28/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.0514 - val_accuracy: 0.9375 - val_loss: 0.1422 - learning_rate: 1.0000e-04\nEpoch 29/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.8978 - loss: 0.1136 - val_accuracy: 0.9089 - val_loss: 0.1627 - learning_rate: 1.0000e-04\nEpoch 30/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.1044 - val_accuracy: 0.9062 - val_loss: 0.1623 - learning_rate: 1.0000e-04\nEpoch 31/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.9131 - loss: 0.0992 - val_accuracy: 0.9089 - val_loss: 0.1546 - learning_rate: 1.0000e-04\nEpoch 32/50\n\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m13s\u001b[0m 108ms/step - accuracy: 0.9375 - loss: 0.0837\nEpoch 32: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0837 - val_accuracy: 0.9089 - val_loss: 0.1545 - learning_rate: 1.0000e-04\nEpoch 33/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 287ms/step - accuracy: 0.9123 - loss: 0.0922 - val_accuracy: 0.9349 - val_loss: 0.1410 - learning_rate: 5.0000e-05\nEpoch 34/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0614 - val_accuracy: 0.9349 - val_loss: 0.1412 - learning_rate: 5.0000e-05\nEpoch 35/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 286ms/step - accuracy: 0.9241 - loss: 0.1011 - val_accuracy: 0.9323 - val_loss: 0.1382 - learning_rate: 5.0000e-05\nEpoch 36/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.0808 - val_accuracy: 0.9323 - val_loss: 0.1389 - learning_rate: 5.0000e-05\nEpoch 37/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.9404 - loss: 0.0886 - val_accuracy: 0.9349 - val_loss: 0.1358 - learning_rate: 5.0000e-05\nEpoch 38/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.1604 - val_accuracy: 0.9349 - val_loss: 0.1358 - learning_rate: 5.0000e-05\nEpoch 39/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.9352 - loss: 0.0821 - val_accuracy: 0.9323 - val_loss: 0.1436 - learning_rate: 5.0000e-05\nEpoch 40/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0573 - val_accuracy: 0.9297 - val_loss: 0.1437 - learning_rate: 5.0000e-05\nEpoch 41/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.9357 - loss: 0.0866 - val_accuracy: 0.9375 - val_loss: 0.1241 - learning_rate: 5.0000e-05\nEpoch 42/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0870 - val_accuracy: 0.9375 - val_loss: 0.1243 - learning_rate: 5.0000e-05\nEpoch 43/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 297ms/step - accuracy: 0.9336 - loss: 0.0787 - val_accuracy: 0.9427 - val_loss: 0.1182 - learning_rate: 5.0000e-05\nEpoch 44/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1079 - val_accuracy: 0.9401 - val_loss: 0.1177 - learning_rate: 5.0000e-05\nEpoch 45/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 299ms/step - accuracy: 0.9360 - loss: 0.0839 - val_accuracy: 0.9583 - val_loss: 0.1104 - learning_rate: 5.0000e-05\nEpoch 46/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0667 - val_accuracy: 0.9583 - val_loss: 0.1107 - learning_rate: 5.0000e-05\nEpoch 47/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 286ms/step - accuracy: 0.9375 - loss: 0.0771 - val_accuracy: 0.9427 - val_loss: 0.1155 - learning_rate: 5.0000e-05\nEpoch 48/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0667 - val_accuracy: 0.9427 - val_loss: 0.1157 - learning_rate: 5.0000e-05\nEpoch 49/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 285ms/step - accuracy: 0.9456 - loss: 0.0775\nEpoch 49: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 288ms/step - accuracy: 0.9456 - loss: 0.0775 - val_accuracy: 0.9427 - val_loss: 0.1134 - learning_rate: 5.0000e-05\nEpoch 50/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.0532 - val_accuracy: 0.9427 - val_loss: 0.1137 - learning_rate: 2.5000e-05\nRestoring model weights from the end of the best epoch: 45.\n\nRunning standard inference...\nRunning TTA inference...\n\nEfficientNetB0_CBAM Results:\n  Parameters:    4,590,938\n  Train Time:    1045.6s (17.4 min)\n  Inference:     632.06ms/image\n  Standard:      Acc=0.9536, F1=0.9158, AUC=0.9733\n  TTA:           Acc=0.9536, F1=0.9008, AUC=0.9777\n  Improvement:   +0.00% accuracy\n\n======================================================================\nTraining MobileNetV2\n======================================================================\nDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nModel parameters: 2,593,092\nEpoch 1/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 500ms/step - accuracy: 0.3998 - loss: 0.6192 - val_accuracy: 0.3932 - val_loss: 0.7063 - learning_rate: 1.0000e-04\nEpoch 2/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6250 - loss: 0.2657 - val_accuracy: 0.4010 - val_loss: 0.7001 - learning_rate: 1.0000e-04\nEpoch 3/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 285ms/step - accuracy: 0.6388 - loss: 0.2876 - val_accuracy: 0.2500 - val_loss: 1.0375 - learning_rate: 1.0000e-04\nEpoch 4/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7812 - loss: 0.2150 - val_accuracy: 0.2396 - val_loss: 1.0781 - learning_rate: 1.0000e-04\nEpoch 5/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 289ms/step - accuracy: 0.7233 - loss: 0.2359 - val_accuracy: 0.4818 - val_loss: 0.6250 - learning_rate: 1.0000e-04\nEpoch 6/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8750 - loss: 0.1463 - val_accuracy: 0.4896 - val_loss: 0.6069 - learning_rate: 1.0000e-04\nEpoch 7/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 290ms/step - accuracy: 0.8048 - loss: 0.1820 - val_accuracy: 0.5417 - val_loss: 0.5376 - learning_rate: 1.0000e-04\nEpoch 8/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8125 - loss: 0.1390 - val_accuracy: 0.5443 - val_loss: 0.5356 - learning_rate: 1.0000e-04\nEpoch 9/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 287ms/step - accuracy: 0.8640 - loss: 0.1457 - val_accuracy: 0.5130 - val_loss: 0.5923 - learning_rate: 1.0000e-04\nEpoch 10/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9062 - loss: 0.0867 - val_accuracy: 0.5078 - val_loss: 0.6008 - learning_rate: 1.0000e-04\nEpoch 11/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 283ms/step - accuracy: 0.8713 - loss: 0.1317 - val_accuracy: 0.3646 - val_loss: 0.8697 - learning_rate: 1.0000e-04\nEpoch 12/50\n\u001b[1m  1/125\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m9s\u001b[0m 74ms/step - accuracy: 0.8438 - loss: 0.0923\nEpoch 12: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8438 - loss: 0.0923 - val_accuracy: 0.3542 - val_loss: 0.8941 - learning_rate: 1.0000e-04\nEpoch 13/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 291ms/step - accuracy: 0.9015 - loss: 0.1138 - val_accuracy: 0.6849 - val_loss: 0.3393 - learning_rate: 5.0000e-05\nEpoch 14/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9375 - loss: 0.0694 - val_accuracy: 0.6849 - val_loss: 0.3408 - learning_rate: 5.0000e-05\nEpoch 15/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 285ms/step - accuracy: 0.9123 - loss: 0.1109 - val_accuracy: 0.6510 - val_loss: 0.4183 - learning_rate: 5.0000e-05\nEpoch 16/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8750 - loss: 0.1563 - val_accuracy: 0.6510 - val_loss: 0.4207 - learning_rate: 5.0000e-05\nEpoch 17/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 286ms/step - accuracy: 0.9300 - loss: 0.0872\nEpoch 17: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 289ms/step - accuracy: 0.9300 - loss: 0.0872 - val_accuracy: 0.5208 - val_loss: 0.6031 - learning_rate: 5.0000e-05\nEpoch 18/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9688 - loss: 0.0624 - val_accuracy: 0.5208 - val_loss: 0.6057 - learning_rate: 2.5000e-05\nEpoch 19/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 284ms/step - accuracy: 0.9302 - loss: 0.0862 - val_accuracy: 0.5833 - val_loss: 0.5052 - learning_rate: 2.5000e-05\nEpoch 20/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9688 - loss: 0.0568 - val_accuracy: 0.5833 - val_loss: 0.5032 - learning_rate: 2.5000e-05\nEpoch 21/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 284ms/step - accuracy: 0.9316 - loss: 0.0876\nEpoch 21: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 286ms/step - accuracy: 0.9316 - loss: 0.0876 - val_accuracy: 0.6302 - val_loss: 0.4576 - learning_rate: 2.5000e-05\nEpoch 22/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8750 - loss: 0.0954 - val_accuracy: 0.6302 - val_loss: 0.4570 - learning_rate: 1.2500e-05\nEpoch 23/50\n\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 284ms/step - accuracy: 0.9299 - loss: 0.0843 - val_accuracy: 0.6771 - val_loss: 0.3939 - learning_rate: 1.2500e-05\nEpoch 23: early stopping\nRestoring model weights from the end of the best epoch: 13.\n\nRunning standard inference...\nRunning TTA inference...\n\nMobileNetV2 Results:\n  Parameters:    2,593,092\n  Train Time:    509.4s (8.5 min)\n  Inference:     488.99ms/image\n  Standard:      Acc=0.6540, F1=0.5611, AUC=0.9387\n  TTA:           Acc=0.5570, F1=0.5411, AUC=0.9239\n  Improvement:   +-9.70% accuracy\n\n======================================================================\nGENERATING VISUALIZATIONS AND ANALYSIS\n======================================================================\n\n1. Plotting confusion matrices...\n   ✓ Saved: confusion_matrices.png/pdf\n2. Plotting training curves...\n   ✓ Saved: training_curves.png/pdf\n3. Plotting model comparisons...\n   ✓ Saved: comparison_*.png/pdf\n\n4. Best Model: EfficientNetB0_CBAM (TTA Acc=0.9536)\n5. Plotting per-class performance...\n   ✓ Saved: per_class_performance.png/pdf\n6. Plotting ROC curves...\n   ✓ Saved: roc_curves.png/pdf\n\n======================================================================\nSTATISTICAL TESTING\n======================================================================\n\nMcNemar's Test (Pairwise Model Comparison):\n  EfficientNetB0 vs EfficientNetB0_SE: p=0.3428 (✗ Not significant)\n  EfficientNetB0 vs EfficientNetB0_CBAM: p=0.1824 (✗ Not significant)\n  EfficientNetB0 vs MobileNetV2: p=0.0000 (✓ Significant)\n  EfficientNetB0_SE vs EfficientNetB0_CBAM: p=1.0000 (✗ Not significant)\n  EfficientNetB0_SE vs MobileNetV2: p=0.0000 (✓ Significant)\n  EfficientNetB0_CBAM vs MobileNetV2: p=0.0000 (✓ Significant)\n\nWilcoxon Test (Standard vs TTA):\n  EfficientNetB0: p=0.0209 (✓ Significant)\n  EfficientNetB0_SE: p=0.0956 (✗ Not significant)\n  EfficientNetB0_CBAM: p=1.0000 (✗ Not significant)\n  MobileNetV2: p=0.0006 (✓ Significant)\n\n95% Confidence Intervals:\n  EfficientNetB0:\n    Standard: [0.8603, 0.9371]\n    TTA:      [0.9005, 0.9644]\n  EfficientNetB0_SE:\n    Standard: [0.8954, 0.9611]\n    TTA:      [0.9215, 0.9773]\n  EfficientNetB0_CBAM:\n    Standard: [0.9268, 0.9804]\n    TTA:      [0.9268, 0.9804]\n  MobileNetV2:\n    Standard: [0.5934, 0.7146]\n    TTA:      [0.4937, 0.6202]\n\n======================================================================\nGRAD-CAM VISUALIZATION\n======================================================================\nGenerating Grad-CAM for EfficientNetB0_CBAM...\n  Using layer: conv2d\n   ✓ Saved: gradcam.png/pdf\n\n======================================================================\nTTA ABLATION STUDY\n======================================================================\nRunning ablation on EfficientNetB0_CBAM...\n  Testing 3 TTA steps...\n    Acc=0.9536, F1=0.9008\n  Testing 6 TTA steps...\n    Acc=0.9578, F1=0.9039\n  Testing 10 TTA steps...\n    Acc=0.9620, F1=0.9142\n  Testing 15 TTA steps...\n    Acc=0.9578, F1=0.9039\n   ✓ Saved: tta_ablation.png/pdf\n\n======================================================================\nFAILURE ANALYSIS\n======================================================================\n\nMisclassification counts:\n  EfficientNetB0: 16 errors (6.8%)\n  EfficientNetB0_SE: 12 errors (5.1%)\n  EfficientNetB0_CBAM: 11 errors (4.6%)\n  MobileNetV2: 105 errors (44.3%)\n\nMost common errors (True → Pred):\n  Fillings → Impacted Tooth: 71 times\n  Fillings → Implant: 23 times\n  Fillings → Cavity: 15 times\n  Implant → Cavity: 9 times\n  Cavity → Impacted Tooth: 8 times\n  Implant → Fillings: 6 times\n  Impacted Tooth → Fillings: 3 times\n  Cavity → Fillings: 3 times\n  Implant → Impacted Tooth: 3 times\n  Impacted Tooth → Cavity: 2 times\n\n======================================================================\nLATEX TABLES FOR PAPER\n======================================================================\n\n--- Dataset Statistics Table ---\n\\begin{table}[htbp]\n\\centering\n\\caption{Dataset Statistics}\n\\begin{tabular}{|l|r|r|r|r|}\n\\hline\n\\textbf{Class} & \\textbf{Train} & \\textbf{Val} & \\textbf{Test} & \\textbf{Total} \\\\ \\hline\nCavity & 194 & 8 & 11 & 213 \\\\ \\hline\nFillings & 2631 & 277 & 154 & 3062 \\\\ \\hline\nImpacted Tooth & 292 & 22 & 19 & 333 \\\\ \\hline\nImplant & 906 & 85 & 53 & 1044 \\\\ \\hline\n\\textbf{Total} & 4023 & 392 & 237 & 4652 \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\n--- Model Comparison Table ---\n\\begin{table*}[htbp]\n\\centering\n\\caption{Model Performance Comparison}\n\\begin{tabular}{|l|r|r|c|c|c|c|}\n\\hline\n\\textbf{Model} & \\textbf{Params} & \\textbf{Inf (ms)} & \\textbf{Std Acc} & \\textbf{TTA Acc} & \\textbf{TTA F1} & \\textbf{AUC} \\\\ \\hline\nEfficientNetB0 & 4,384,679 & 801.3 & 0.8987 & 0.9325 & 0.8531 & 0.9893 \\\\ \\hline\nEfficientNetB0 SE & 4,590,839 & 725.3 & 0.9283 & 0.9494 & 0.8982 & 0.9812 \\\\ \\hline\nEfficientNetB0 CBAM & 4,590,938 & 632.1 & 0.9536 & 0.9536 & 0.9008 & 0.9777 \\\\ \\hline\nMobileNetV2 & 2,593,092 & 489.0 & 0.6540 & 0.5570 & 0.5411 & 0.9239 \\\\ \\hline\n\\end{tabular}\n\\end{table*}\n\n--- Per-Class Metrics Table ---\n\\begin{table}[htbp]\n\\centering\n\\caption{Per-Class Performance (EfficientNetB0 CBAM)}\n\\begin{tabular}{|l|c|c|c|}\n\\hline\n\\textbf{Class} & \\textbf{Precision} & \\textbf{Recall} & \\textbf{F1-Score} \\\\ \\hline\nCavity & 0.8000 & 0.7273 & 0.7619 \\\\ \\hline\nFillings & 0.9803 & 0.9675 & 0.9739 \\\\ \\hline\nImpacted Tooth & 0.9000 & 0.9474 & 0.9231 \\\\ \\hline\nImplant & 0.9273 & 0.9623 & 0.9444 \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\n--- Attention Ablation Table ---\n\\begin{table}[htbp]\n\\centering\n\\caption{Attention Mechanism Ablation}\n\\begin{tabular}{|l|c|c|c|}\n\\hline\n\\textbf{Model} & \\textbf{TTA Acc} & \\textbf{Macro-F1} & \\textbf{AUC} \\\\ \\hline\nEfficientNetB0 & 0.9325 & 0.8531 & 0.9893 \\\\ \\hline\nEfficientNetB0 SE & 0.9494 & 0.8982 & 0.9812 \\\\ \\hline\nEfficientNetB0 CBAM & 0.9536 & 0.9008 & 0.9777 \\\\ \\hline\n\\end{tabular}\n\\end{table}\n\n======================================================================\nSAVING RESULTS\n======================================================================\n   ✓ Saved: results.json\n\n======================================================================\nEXPERIMENT COMPLETE!\n======================================================================\n\nBest Model: EfficientNetB0_CBAM\n  TTA Accuracy: 0.9536\n  TTA Macro-F1: 0.9008\n  TTA AUC:      0.9777\n\nGenerated Files:\n  Models:  models/best_*.keras (4 files)\n  Figures: figures/*.png & *.pdf (10 files)\n  Data:    results.json\n\n✓ All analyses completed successfully!\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}